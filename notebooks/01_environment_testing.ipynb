{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Environment Testing Notebook\n",
        "\n",
        "This notebook is for testing and debugging the REACH simulation environments.\n",
        "\n",
        "Use this to:\n",
        "- Test environment setup\n",
        "- Visualize observations and actions\n",
        "- Debug reward functions\n",
        "\n",
        "## FIRST TIME SETUP\n",
        "\n",
        "After you've cloned this repo, go to the root directory of the project (`cd PATH/TO/reach/`)\n",
        "\n",
        "Create a Python Virtual Environment (venv)\n",
        "\n",
        "`python -m venv .`\n",
        "\n",
        "VSCode might give you a popup about there being a new environment, asking if you want to set it to default. Select yes.\n",
        "<hr>\n",
        "Once you've created the environment, you don't need to do it again. However, you'll need to activate it each time you begin work (VSCode should do this automatically).\n",
        "\n",
        "If you need to do it manually:\n",
        "\n",
        "Unix: `source ./bin/activate`\n",
        "\n",
        "Windows PS: `./Scripts/Activate.ps1`\n",
        "\n",
        "This virtual environment keeps all the packages you install local to this project.\n",
        "<hr>\n",
        "\n",
        "In the top right of this notebook, you'll see a selector for the Python kernel (something like Python 3.12.1). Click on this and select \"Select another kernel\", then \"Python Environments\", then \"reach\".\n",
        "\n",
        "This ensures the Jupyter notebook runs your code inside the virtual environment.\n",
        "<hr>\n",
        "\n",
        "Next, you'll need to install the required packages.\n",
        "\n",
        "`pip install -r requirements.txt`\n",
        "<hr>\n",
        "\n",
        "Once you've completed the above steps, you should be able to test your environment. You can click \"Run All\" at the top or run the blocks one by one.\n",
        "\n",
        "If something doesn't work, try to do some research and see if you need to install prerequisite packages for your system. Otherwise, reach out to a REACH developer for assistance.\n",
        "\n",
        "## 1. Test Gymnasium and SB3\n",
        "\n",
        "Run the below code to test gymnasium and sb3 installations.\n",
        "\n",
        "There will be no window and it should only take about 3 seconds to run.\n",
        "\n",
        "NOTE: If you have a CUDA enabled GPU (NVIDIA), run `pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121` to use GPU acceleration."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "def test_no_view():\n",
        "    env = gym.make(\"CartPole-v1\")\n",
        "    model = PPO(\"MlpPolicy\", env, verbose=1, device=\"auto\")\n",
        "    model.learn(total_timesteps=500) # Increase this value to train longer, 500 takes about 1 minute, 5000 takes about 2.5 minutes\n",
        "\n",
        "    obs, _ = env.reset()\n",
        "    for _ in range(10):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        if terminated or truncated:\n",
        "            obs, _ = env.reset()\n",
        "\n",
        "    env.close()\n",
        "    return model\n",
        "\n",
        "model = test_no_view()\n",
        "\n",
        "print(\"✅ Completed cart pole test successfully!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Test visualization\n",
        "\n",
        "Now, test the human view of the above code. This should create a pygame window (you might need to look for it!) and will take about 1 minute to run.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def test_vis():\n",
        "    env = gym.make(\"CartPole-v1\", render_mode=\"human\")\n",
        "    model = PPO(\"MlpPolicy\", env, verbose=0, device=\"auto\")\n",
        "    model.learn(total_timesteps=100) # Increase this value to train longer, 100 takes about 40 seconds, 500 takes about 1 minute\n",
        "\n",
        "    obs, _ = env.reset()\n",
        "    for _ in range(10):\n",
        "        action, _ = model.predict(obs, deterministic=True)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        if terminated or truncated:\n",
        "            obs, _ = env.reset()\n",
        "\n",
        "    env.close()\n",
        "    return model\n",
        "\n",
        "model = test_vis()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Train the model\n",
        "\n",
        "Train the model for about 5-10 minutes and save its policy to ppo_cartpole.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "def train_model():\n",
        "    # 8 parallel environments\n",
        "    env = DummyVecEnv([lambda: gym.make(\"CartPole-v1\") for _ in range(8)])\n",
        "    model = PPO(\"MlpPolicy\", env, verbose=0, device=\"auto\")  # verbose=0 to reduce logging\n",
        "\n",
        "    model.learn(total_timesteps=500_000) # This will take some time to complete\n",
        "    model.save(\"ppo_cartpole\")\n",
        "    env.close()\n",
        "\n",
        "    return model\n",
        "\n",
        "model = train_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Load model and record video\n",
        "\n",
        "This will load the policy we saved in the last step and it will run some tests while recording.\n",
        "\n",
        "The output video will be named `cartpole_trained.mp4`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
        "\n",
        "video_filename = \"cartpole_trained.mp4\"\n",
        "\n",
        "def load_and_record_model():\n",
        "    env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
        "    model = PPO.load(\"ppo_cartpole.zip\", env=env, device=\"cuda\")\n",
        "\n",
        "    fps = 60\n",
        "\n",
        "    obs, _ = env.reset()\n",
        "    first_frame = env.render()\n",
        "    height, width, _ = first_frame.shape\n",
        "\n",
        "    writer = FFMPEG_VideoWriter(\n",
        "        video_filename,\n",
        "        size=(width, height),\n",
        "        fps=fps,\n",
        "        codec=\"libx264\"\n",
        "    )\n",
        "\n",
        "    writer.write_frame(first_frame)\n",
        "\n",
        "    num_episodes = 10\n",
        "    max_steps_per_episode = 500\n",
        "\n",
        "    for ep in range(num_episodes):\n",
        "        obs, _ = env.reset()\n",
        "        for step in range(max_steps_per_episode):\n",
        "            action, _ = model.predict(obs, deterministic=True)  # deterministic for video\n",
        "            obs, reward, terminated, truncated, info = env.step(action)\n",
        "\n",
        "            frame = env.render()\n",
        "            if frame is not None:\n",
        "                writer.write_frame(frame)\n",
        "\n",
        "            if terminated or truncated:\n",
        "                break\n",
        "\n",
        "    env.close()\n",
        "    writer.close()\n",
        "    return model\n",
        "\n",
        "model = load_and_record_model()\n",
        "\n",
        "print(f\"✅ Video saved as {video_filename}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "reach",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
